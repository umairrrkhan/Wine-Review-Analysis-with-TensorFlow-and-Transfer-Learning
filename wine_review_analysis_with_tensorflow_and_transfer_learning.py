# -*- coding: utf-8 -*-
"""Wine Review Analysis with TensorFlow and Transfer Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T601Qa3uHVLNfguIxawarWBQihozcDz8
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_hub as hub
import pandas as pd

df = pd.read_csv('wine-reviews.csv', usecols = ['country' ,'description',  'points' , 'price' , 'variety' , 'winery'])

df.head()

df = df.dropna(subset=[ 'description', 'points'])

df.head()

plt.hist(df.points , bins= 20)  # this line creates a histogram using the 'points' column data from the DataFrame 'df'.
plt.xlabel('N')
plt.ylabel('Points')
plt.show()

df['labels'] = (df.points>= 90).astype(int)

df = df[['labels','description']]
# the entire line of code assigns labels of 1 to rows where 'points' is 90 or greater and labels of 0 to rows where
#'points' is less than 90, and stores these labels in the new 'labels' column in the DataFrame 'df'

train, val, test = np.split(df.sample(frac=1), [int(0.8*len(df)), int(0.9*len(df))])

# len(train), len(val) , len(test)

def df_to_dataset(dataframe, shuffle=True, batch_size=1024):
  df = dataframe.copy()
  labels = df.pop('labels')
  df = df["description"]
  ds = tf.data.Dataset.from_tensor_slices((df, labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  ds = ds.prefetch(tf.data.AUTOTUNE)
  return ds

train_data = df_to_dataset(train)
valid_data = df_to_dataset(val)
test_data = df_to_dataset(test)

# embedding  and text

embedding = "https://tfhub.dev/google/nnlm-en-dim50/2"
hub_layer = hub.KerasLayer(embedding, dtype=tf.string, trainable=True)

hub_layer(list(train_data)[0][0])

model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dropout(0.4))
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dropout(0.4))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

model.evaluate(train_data)

model.evaluate(valid_data)

history = model.fit(train_data, epochs=5, validation_data=valid_data)

plt.plot(history.history['accuracy'], label = 'Training_acc')
plt.plot(history.history['val_accuracy'], label = 'Validation_acc')
plt.title('Accuracy Model')
plt.ylabel('Accuracy')
plt.xlabel('epoch')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label = 'Training_loss')
plt.plot(history.history['val_loss'], label = 'Validation_loss')
plt.title('loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend()
plt.show()

# lstm

encoder = tf.keras.layers.TextVectorization(max_tokens=2000)
encoder.adapt(train_data.map(lambda text, label: text))

vocab = np.array(encoder.get_vocabulary())
vocab[:20]

model = tf.keras.Sequential([
    encoder,
    tf.keras.layers.Embedding(
        input_dim=len(encoder.get_vocabulary()),
        output_dim=32,
        mask_zero=True
    ),
    tf.keras.layers.LSTM(32),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

model.evaluate(train_data)
model.evaluate(valid_data)

history = model.fit(train_data, epochs=5, validation_data=valid_data)

model.evaluate(test_data)